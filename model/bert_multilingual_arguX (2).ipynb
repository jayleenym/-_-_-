{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_multilingual_arguX.ipynb","private_outputs":true,"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SKfCEvSbfgsh"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMQ7613efnOX"},"source":["import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jhj88yqfoi1"},"source":["# 구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZjRpz8qRfp3J"},"source":["# 데이터셋 불러오기\n","import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/데캡디/review_data_1700_1217.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLN8RGxtgE_D"},"source":["# column명 변경\n","df.rename(columns={'review':'content', 'label':'label'}, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJ3RxVUigLOG"},"source":["# label encoding\n","df.loc[(df['label'] == '0.0'), 'label'] = 0 \n","df.loc[(df['label'] == '1.0'), 'label'] = 1\n","\n","\n","\n","# list형태로 데이터 저장 -> [content, label] 형태\n","data_list = []\n","for q, label in zip(df['content'], df['label'])  :\n","    data = []\n","    data.append(str(q)) # str타입으로 변환, 안 해주면 나중에 타입변환할 때 오류남\n","    data.append(str(label))\n","\n","    data_list.append(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9UIW5cSgV7z"},"source":["df = df.astype({'label':'int'})\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGf-4w-VgYeg"},"source":["df['label'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCJKXIgSr1t0"},"source":["df_0 = df[df['label'] == 0]\n","df_1 = df[df['label'] == 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xHA37bOr72e"},"source":["df = pd.concat([df_0[:565], df_1])\n","df = df.sample(frac=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KENaflnFsNOv"},"source":["#df.to_csv(\"/content/drive/Shareddrives/실전기계_project/data_base_add_downsampling.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmXVjpeOgkwZ"},"source":["document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in df['content']]\n","document_bert[:5]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aanmUqcwgvuf"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in document_bert]\n","print(tokenized_texts[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJolmhapg0-P"},"source":["MAX_LEN = 256\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n","input_ids[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97qtqa-2g3sa"},"source":["attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","    \n","print(attention_masks[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjrRfJi6g6PK"},"source":["train_inputs, validation_inputs, train_labels, validation_labels = \\\n","train_test_split(input_ids, df['label'].values, random_state=42, test_size=0.2)\n","\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=42, \n","                                                       test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V3PtEjl_g9rO"},"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ag36yy4Rg_mB"},"source":["BATCH_SIZE = 16\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVzH7td2hBnQ"},"source":["if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWw0h91whEO9"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1Rc4lnyhGUY"},"source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 1e-6, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 20\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","# lr 조금씩 감소시키는 스케줄러\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0.1,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiuwPQtDhIWn"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","# 시간 표시 함수\n","def format_time(elapsed):\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKsgXXdOhLlJ"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 모델 학습시키기\n","train_loss_list = []\n","#test_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","\n","    train_acc = 0\n","    nb_train_steps = 0   \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n"," #       print(loss)\n","\n","        # train acc 계산\n"," #       loss = loss.detach().cpu().numpy()\n"," #       label_ids = b_labels.to('cpu').numpy()\n","\n","#        tmp_eval_accuracy = flat_accuracy(loss, label_ids)\n","#        train_acc += tmp_eval_accuracy\n","#        nb_train_steps += 1\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    \n","#    print(\" train acc: {0:.2f}\".format(train_acc/nb_train_steps))\n","\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","    train_loss_list.append(avg_train_loss)\n","#    train_acc_list.append(train_acc/nb_train_steps)\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    test_acc_list.append(eval_accuracy/nb_eval_steps)\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBzo5Ejrh8eR"},"source":["import matplotlib.pyplot as plt\n","plt.plot(np.arange(0.0, 20.0, 1.0), train_loss_list, np.arange(0.0, 20.0, 1.0), test_acc_list, 'r-')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"TucNJRXjoPjP"},"execution_count":null,"outputs":[]}]}